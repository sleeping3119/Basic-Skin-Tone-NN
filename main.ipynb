{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing dataset...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATASET_PATH = \"dataset\"  \n",
    "IMG_SIZE = (128, 128)  \n",
    "CLASSES = [\"Light\", \"Very Light\", \"Medium\",\"Deep\", \"Very Deep\"]  \n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:  return None \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, IMG_SIZE)  # Resize to uniform size\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(DATASET_PATH, class_name)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = preprocess_image(img_path)\n",
    "            images.append(img)\n",
    "            labels.append(class_name)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "print(\"Loading and preprocessing dataset...\")\n",
    "images, labels = load_dataset()\n",
    "print(\"Data Loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a898607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489, 128, 128, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbe277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 128 * 128 * 3\n",
    "HIDDEN_SIZE = 64\n",
    "OUTPUT_SIZE = len(CLASSES)          \n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def one_hot(labels, class_list):\n",
    "    mapping = {c: i for i, c in enumerate(class_list)}\n",
    "    y = np.zeros((len(labels), len(class_list)))\n",
    "    for idx, lab in enumerate(labels):\n",
    "        y[idx, mapping[lab]] = 1\n",
    "    return y\n",
    "\n",
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Xavier/Glorot initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / (input_size + hidden_size))\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / (hidden_size + output_size))\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Layer 1\n",
    "        self.Z1 = X.dot(self.W1) + self.b1          # pre-activation\n",
    "        self.A1 = sigmoid(self.Z1)                  # activation\n",
    "        \n",
    "        # Layer 2\n",
    "        self.Z2 = self.A1.dot(self.W2) + self.b2     # pre-activation\n",
    "        self.A2 = softmax(self.Z2)                   # output probabilities\n",
    "        return self.A2\n",
    "\n",
    "    def compute_loss(self, Y_pred, Y_true):\n",
    "        # Cross-entropy loss\n",
    "        m = Y_true.shape[0]\n",
    "        log_likelihood = -np.log(Y_pred + 1e-9) * Y_true\n",
    "        loss = np.sum(log_likelihood) / m\n",
    "        return loss\n",
    "\n",
    "    def backward(self, X, Y_true):\n",
    "        m = Y_true.shape[0]\n",
    "        \n",
    "        # dZ2 = A2 - Y\n",
    "        dZ2 = (self.A2 - Y_true) / m\n",
    "        # gradients W2, b2\n",
    "        dW2 = self.A1.T.dot(dZ2)\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "        \n",
    "        # backprop into hidden layer\n",
    "        dA1 = dZ2.dot(self.W2.T)\n",
    "        dZ1 = dA1 * sigmoid_derivative(self.Z1)\n",
    "        # gradients W1, b1\n",
    "        dW1 = X.T.dot(dZ1)\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "        \n",
    "        self.W2 -= LEARNING_RATE * dW2\n",
    "        self.b2 -= LEARNING_RATE * db2\n",
    "        self.W1 -= LEARNING_RATE * dW1\n",
    "        self.b1 -= LEARNING_RATE * db1\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.forward(X)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "def get_batches(X, Y, batch_size):\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "\n",
    "# images, labels = load_dataset()  \n",
    "X = images.reshape(len(images), -1)  # flatten\n",
    "Y = one_hot(labels, CLASSES)\n",
    "\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "X, Y = X[perm], Y[perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73100c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 — Loss: 1.4988\n",
      "Epoch 2/25 — Loss: 1.2463\n",
      "Epoch 3/25 — Loss: 1.1151\n",
      "Epoch 4/25 — Loss: 1.0236\n",
      "Epoch 5/25 — Loss: 0.9539\n",
      "Epoch 6/25 — Loss: 0.8990\n",
      "Epoch 7/25 — Loss: 0.8534\n",
      "Epoch 8/25 — Loss: 0.8141\n",
      "Epoch 9/25 — Loss: 0.7790\n",
      "Epoch 10/25 — Loss: 0.7470\n",
      "Epoch 11/25 — Loss: 0.7174\n",
      "Epoch 12/25 — Loss: 0.6897\n",
      "Epoch 13/25 — Loss: 0.6637\n",
      "Epoch 14/25 — Loss: 0.6392\n",
      "Epoch 15/25 — Loss: 0.6160\n",
      "Epoch 16/25 — Loss: 0.5940\n",
      "Epoch 17/25 — Loss: 0.5731\n",
      "Epoch 18/25 — Loss: 0.5533\n",
      "Epoch 19/25 — Loss: 0.5345\n",
      "Epoch 20/25 — Loss: 0.5165\n",
      "Epoch 21/25 — Loss: 0.4993\n",
      "Epoch 22/25 — Loss: 0.4829\n",
      "Epoch 23/25 — Loss: 0.4672\n",
      "Epoch 24/25 — Loss: 0.4523\n",
      "Epoch 25/25 — Loss: 0.4380\n",
      "Training Accuracy on 70% data: 89.92%\n"
     ]
    }
   ],
   "source": [
    "split_index = int(0.7 * len(X))\n",
    "X_train, Y_train = X[:split_index], Y[:split_index]\n",
    "X_test, Y_test = X[split_index:], Y[split_index:]\n",
    "\n",
    "\n",
    "nn = SimpleNN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_loss = 0\n",
    "    for X_batch, Y_batch in get_batches(X_train, Y_train, BATCH_SIZE):\n",
    "        Y_pred = nn.forward(X_batch)\n",
    "        loss = nn.compute_loss(Y_pred, Y_batch)\n",
    "        nn.backward(X_batch, Y_batch)\n",
    "        epoch_loss += loss * X_batch.shape[0]\n",
    "    epoch_loss /= X_train.shape[0]\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} — Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "train_preds = nn.predict(X_train)\n",
    "train_acc = np.mean(train_preds == np.argmax(Y_train, axis=1))\n",
    "print(f\"Training Accuracy on 70% data: {train_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be38e77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on 30% data: 80.09%\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "test_preds = nn.predict(X_test)\n",
    "test_labels = np.argmax(Y_test, axis=1)\n",
    "test_acc = np.mean(test_preds == test_labels)\n",
    "print(f\"Test Accuracy on 30% data: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f854e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m unknown_images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m img_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(UNKNOWN_PATH):\n\u001b[0;32m      8\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(UNKNOWN_PATH, file)\n\u001b[0;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m preprocess_image(img_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "UNKNOWN_PATH = \"unknown_images\"  # Folder with images of unknown skin tones\n",
    "output_log_path = \"predictions_log.txt\"\n",
    "\n",
    "unknown_images = []\n",
    "img_names = []\n",
    "\n",
    "for file in os.listdir(UNKNOWN_PATH):\n",
    "    img_path = os.path.join(UNKNOWN_PATH, file)\n",
    "    img = preprocess_image(img_path)\n",
    "    if img is not None:\n",
    "        unknown_images.append(img)\n",
    "        img_names.append(file)\n",
    "\n",
    "unknown_images = np.array(unknown_images).reshape(len(unknown_images), -1)\n",
    "\n",
    "\\\n",
    "\n",
    "probs = nn.forward(unknown_images)\n",
    "predictions = np.argmax(probs, axis=1)\n",
    "confidences = np.max(probs, axis=1)\n",
    "\n",
    "\n",
    "with open(output_log_path, \"w\") as f:\n",
    "    for name, pred, conf in zip(img_names, predictions, confidences):\n",
    "        f.write(f\"{name}: Predicted Skin Tone = {CLASSES[pred]} | Confidence = {conf:.4f}\\n\")\n",
    "\n",
    "print(f\"Prediction log saved to: {output_log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
